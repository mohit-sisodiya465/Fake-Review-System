import pandas as pd
from langdetect import detect
from googletrans import Translator
from transformers import pipeline
import multiprocessing
import asyncio  # Import asyncio for handling async functions

# Initialize Translator and Sentiment Analyzer
translator = Translator()
sentiment_analyzer = pipeline("sentiment-analysis")

def detect_language(text):
    """Detect the language of the input text."""
    try:
        return detect(text)
    except:
        return "unknown"

async def translate_to_english(text, source_language):
    """Translate text to English if needed."""
    try:
        if source_language != "en":
            # Await the translation coroutine
            translated = await translator.translate(text, src=source_language, dest="en")
            return translated.text
        return text  # Already in English
    except Exception as e:
        print(f"Translation Error: {e}")
        return text


# Use a model with a larger input size (e.g., Longformer)
sentiment_analyzer = pipeline("sentiment-analysis", model="allenai/longformer-base-4096")
""""
def analyze_sentiment(text):
    Analyze sentiment using a model with a larger input size.
    try:
        result = sentiment_analyzer(text)
        return result[0]['label'], result[0]['score']
    except Exception as e:
        print(f"Sentiment Analysis Error: {e}")
        return "Neutral", 0.0
    
"""   
def analyze_sentiment(text):
    
    try:
        result = sentiment_analyzer(text)
        return result[0]['label'], result[0]['score']
    except Exception as e:
        print(f"Sentiment Analysis Error: {e}")
        return "Neutral", 0.0

def guess_human_or_ai(text):
    """Guess whether the review is human-written or AI-written."""
    # Placeholder function: Implement your own logic here
    import random
    return random.choice(["human", "ai"])

async def process_review(review):
    """Process a review: detect language, translate, analyze sentiment, and guess human/AI."""
    detected_lang = detect_language(review)
    translated_text = await translate_to_english(review, detected_lang)  # Await the translation
    sentiment, confidence = analyze_sentiment(translated_text)
    author_type = guess_human_or_ai(translated_text)
    
    return review, detected_lang, translated_text, sentiment, confidence, author_type

async def process_large_dataset(input_file, output_file, num_workers=4):
    """Process large dataset using multiprocessing and save results to CSV."""
    df = pd.read_csv(input_file)  # Load dataset (Assuming it has a column 'review')

    # Use asyncio.gather to process reviews concurrently
    tasks = [process_review(review) for review in df['review'].tolist()]
    results = await asyncio.gather(*tasks)

    # Convert results to DataFrame
    df_processed = pd.DataFrame(results, columns=["original_text", "language", "translated_text", "sentiment", "confidence", "author_type"])

    # Save to CSV
    df_processed.to_csv(output_file, index=False)
    print(f"Processing completed! Results saved to {output_file}")

# Example Usage
if __name__ == "__main__":
    # Run the async function using asyncio.run
    asyncio.run(process_large_dataset("total_reviews.csv", "processed_reviews.csv", num_workers=4))